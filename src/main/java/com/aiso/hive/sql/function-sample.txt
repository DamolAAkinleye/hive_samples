 当数据集非常大的时候，我们需要找一个子集来加快数据分析。此时我们需要数据采集工具以获得需要的子集。

1. Random sampling 使用RAND()函数和LIMIT关键字来获取样例数据。

使用DISTRIBUTE和SORT关键字来保证数据是随机分散到mapper和reducer的。ORDER BY RAND()语句可以获得同样的效果，但是性能没这么高。 --Syntax： SELECT * FROM <Table_Name> DISTRIBUTE BY RAND() SORT BY RAND() LIMIT <N rows to sample>;

2. Bucket table sampling 该方式是最佳化采样bucket表。RAND()函数也可以用来采样整行。如果采样列同时使用了CLUSTERED BY，使用TABLESAMPLE语句会更有效率。

--Syntax： SELECT * FROM <Table_Name> TABLESAMPLE(BUCKET <specified bucket number to sample> OUT OF <total number of buckets> ON [colname|RAND()]) table_alias;

 hive> CREATE TABLE employee_id_buckets ( name string, employee_id int, work_place ARRAY<string>, sex_age STRUCT<sex:string,age:int>, skills_score MAP<string,int>, depart_title MAP<string,ARRAY<string >> ) CLUSTERED BY (employee_id) INTO 2 BUCKETS ROW FORMAT DELIMITED FIELDS TERMINATED BY '|' COLLECTION ITEMS TERMINATED BY ',' MAP KEYS TERMINATED BY ':';
INSERT OVERWRITE TABLE employee_id_buckets SELECT * FROM employee_id;
SELECT name FROM employee_id_buckets TABLESAMPLE(BUCKET 1 OUT OF 2 ON rand()) a;

3. Block sampling 该方式允许Hive随机抽取N行数据，数据总量的百分比（n百分比）或N字节的数据。

--Syntax： SELECT * FROM <Table_Name> TABLESAMPLE(N PERCENT|ByteLengthLiteral|N ROWS) s; --ByteLengggthLiteral： --(Digit)+ ('b' | 'B' | 'k' | 'K' | 'm' | 'M' | 'g' | 'G')

例：按行抽样 hive> SELECT name FROM employee_id_buckets TABLESAMPLE(4 ROWS) a;


例：按数据量百分比抽样 hive> SELECT name FROM employee_id_buckets TABLESAMPLE(10 PERCENT) a; 注：此方法有待考证，在Hive0.11.0中将所有25条数据全取出来了，在Hive0.13.0中取出了其中的12条，但是都不符合要求！！

例：按数据大小采样 hive> SELECT name FROM employee_id_buckets TABLESAMPLE(1M) a;

总结 聚合和抽样，特别是聚合函数，在大数据处理过程中是处理数据的主要方法。通过自由的条件限制以及聚合函数组合，基本能完成任意要求的数据处理或分组。


关于像解析函数之类的使用比较复杂一点的处理方式需要进行更深一步的了解和运用。希望本文能提供到一定的帮助！
