  -- Hive中导出数据主要分为两大类，分别是导出数据到linux系统和导出数据到hdfs文件系统上。另外也可以认为导出数据到其他hive表也算导出数据(不过该方式也是导入数据)。命令如下：


INSERT OVERWRITE [LOCAL] DIRECTORY directory1 [row format row_format] [stored as file_format] SELECT ... FROM ...
-- 注意：hive导出数据支持一次导出到多个文件夹中，同多表同时导入数据一样。


EXPORT TABLE tablename [PARTITION (part_column="value"[, ...])]
  TO 'export_target_path' [ FOR replication('eventid') ]

export table emp to '/export/' ;

insert overwrite [local] director select ...

 insert  overwrite  local directory '/home/beifeng/emp/'
		row format delimited fields terminated by "\t"
		select * from emp ;
-- * local 	表示导出文件到本地目录
-- * 不加local 表示导出到HDFS上面


-- hadoop shell




方式一: hadoop命令导出

hadoop fs -get hdfs://hadoop000:8020/data/page_views2   pv2


方式二:通过insert...directory导出 【spark暂不支持】

导出到本地：

INSERT OVERWRITE LOCAL directory '/home/spark/hivetmp/'
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' LINES TERMINATED BY '\n'
select * from page_views;
导出到HDFS：

INSERT OVERWRITE directory '/hivetmp/'
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' LINES TERMINATED BY '\n'
select * from page_views;
报错：cannot recognize input near 'ROW' 'FORMAT' 'DELIMITED' in select clause

INSERT OVERWRITE directory '/hivetmp/'
select * from page_views;
注意： 导出到本地可以通过ROW FORMAT来设置分隔符,导出到HDFS是不能设置分隔符的；



方式三: shell命令 + 管道(hive -f/-e | sed/grep/awk > file)

hive -e "select * from page_views limit 5"
hive -S -e "select * from page_views limit 5" | grep B58W48U4WKZCJ5D1T3Z9ZY88RU7QA7B1
hive -S -e "select * from page_views limit 5" | grep B58W48U4WKZCJ5D1T3Z9ZY88RU7QA7B1 > file